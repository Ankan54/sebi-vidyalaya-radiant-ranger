{% extends "base.html" %}

{% block title %}{{ exam_name }} - SEBI Vidyalaya{% endblock %}

{% block head %}
<style>
.chat-container {
    height: calc(100vh - 200px);
    display: flex;
    flex-direction: column;
}

.chat-messages {
    flex: 1;
    overflow-y: auto;
    padding: 20px;
    background: #f8f9fa;
}

.message {
    margin-bottom: 20px;
    animation: fadeInUp 0.3s ease-out;
}

.message-user {
    text-align: right;
}

.message-ai {
    text-align: left;
}

.message-bubble {
    display: inline-block;
    max-width: 70%;
    padding: 12px 16px;
    border-radius: 18px;
    position: relative;
}

.message-user .message-bubble {
    background: var(--sebi-navy);
    color: white;
}

.message-ai .message-bubble {
    background: white;
    color: var(--sebi-navy);
    border: 1px solid #e9ecef;
}

.message-header {
    font-size: 0.85rem;
    margin-bottom: 5px;
    opacity: 0.7;
}

.typing-indicator {
    display: flex;
    align-items: center;
    padding: 10px 16px;
    background: white;
    border-radius: 18px;
    max-width: 70px;
}

.typing-dots {
    display: flex;
    gap: 4px;
}

.typing-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: #adb5bd;
    animation: typing 1.4s infinite;
}

.typing-dot:nth-child(2) { animation-delay: 0.2s; }
.typing-dot:nth-child(3) { animation-delay: 0.4s; }

@keyframes typing {
    0%, 60%, 100% { transform: translateY(0); }
    30% { transform: translateY(-10px); }
}

@keyframes fadeInUp {
    from {
        opacity: 0;
        transform: translateY(20px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}
</style>
{% endblock %}

{% block content %}
<div class="container-fluid px-0">
    <!-- Page Header -->
    <div class="page-header bg-sebi-navy text-white py-3">
        <div class="container">
            <div class="row align-items-center">
                <div class="col">
                    <nav aria-label="breadcrumb">
                        <ol class="breadcrumb mb-0">
                            <li class="breadcrumb-item">
                                <a href="{{ url_for('landing') }}" class="text-sebi-gold">
                                    <i class="fas fa-home"></i> Home
                                </a>
                            </li>
                            <li class="breadcrumb-item active text-white">{{ exam_name }}</li>
                        </ol>
                    </nav>
                    <h4 class="mb-0 mt-2">
                        <i class="fas fa-robot me-2 text-sebi-gold"></i>
                        Smart Tutor - Ask anything about SEBI in your preferred language
                    </h4>
                </div>
            </div>
        </div>
    </div>

    <!-- Chat Interface -->
    <div class="chat-container">
        <!-- Chat Messages -->
        <div class="chat-messages" id="chatMessages">
            <!-- Welcome Message -->
            <div class="message message-ai">
                <div class="message-header">
                    <i class="fas fa-robot me-1"></i> AI Tutor
                </div>
                <div class="message-bubble">
                    <div class="mb-2">
                        ðŸ¤– Welcome! I'm your SEBI tutor for <strong>{{ exam_name }}</strong>. You can:
                    </div>
                    <ul class="mb-0">
                        <li>Ask questions by typing or speaking</li>
                        <li>Upload images of documents or questions</li>
                        <li>Switch languages anytime</li>
                    </ul>
                </div>
            </div>

            <!-- Load existing messages -->
            {% for message in messages %}
            <div class="message message-{{ message.message_type }}">
                <div class="message-header">
                    {% if message.message_type == 'user' %}
                        <i class="fas fa-user me-1"></i> You
                    {% else %}
                        <i class="fas fa-robot me-1"></i> AI Tutor
                    {% endif %}
                    <span class="text-muted ms-2">{{ message.timestamp.strftime('%H:%M') }}</span>
                </div>
                <div class="message-bubble">
                    {% if message.content_type == 'image' and message.file_path %}
                        <div class="mb-2">
                            <i class="fas fa-image me-1"></i>
                            {{ message.meta_data.original_name if message.meta_data else 'Uploaded Image' }}
                        </div>
                    {% endif %}
                    {{ message.content }}
                </div>
            </div>
            {% endfor %}
        </div>

        <!-- Input Area -->
        <div class="chat-input-area bg-white border-top">
            <div class="container py-3">
                <!-- File Upload Status -->
                <div id="uploadStatus" class="alert alert-info d-none">
                    <i class="fas fa-spinner fa-spin me-2"></i>
                    Uploading file...
                </div>

                <!-- Voice Status -->
                <div id="voiceStatus" class="alert alert-warning d-none">
                    <div class="d-flex align-items-center">
                        <i class="fas fa-microphone fa-pulse me-2"></i>
                        <span id="voiceStatusText">Listening...</span>
                        <button class="btn btn-sm btn-outline-secondary ms-auto" onclick="stopRecording()">
                            <i class="fas fa-stop"></i> Stop
                        </button>
                    </div>
                    <div id="transcriptionPreview" class="mt-2 small text-muted"></div>
                </div>

                <!-- Input Controls -->
                <div class="input-group">
                    <label for="fileInput" class="btn btn-outline-sebi-navy" title="Upload Image">
                        <i class="fas fa-paperclip"></i>
                    </label>
                    <input type="file" id="fileInput" class="d-none" accept="image/*,.pdf">
                    
                    <button class="btn btn-outline-sebi-navy" id="voiceBtn" onclick="toggleRecording()" title="Voice Input">
                        <i class="fas fa-microphone"></i>
                    </button>
                    
                    <input type="text" class="form-control" id="messageInput" 
                           placeholder="Type your question here..." 
                           onkeypress="handleKeyPress(event)">
                    
                    <button class="btn btn-sebi-primary" onclick="sendMessage()" id="sendBtn">
                        <i class="fas fa-paper-plane"></i>
                    </button>
                </div>

                <!-- Quick Actions -->
                <div class="quick-actions mt-2">
                    <button class="btn btn-sm btn-outline-secondary me-2" onclick="askFollowUp()">
                        <i class="fas fa-redo me-1"></i> Ask follow-up
                    </button>
                    <button class="btn btn-sm btn-outline-secondary me-2" onclick="takeNotes()">
                        <i class="fas fa-sticky-note me-1"></i> Take Notes
                    </button>
                    <button class="btn btn-sm btn-outline-secondary" onclick="readAloud()">
                        <i class="fas fa-volume-up me-1"></i> Read Aloud
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Image Preview Modal -->
<div class="modal fade" id="imagePreviewModal" tabindex="-1">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Image Preview</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
            </div>
            <div class="modal-body text-center">
                <img id="previewImage" class="img-fluid" src="" alt="Preview">
                <div class="mt-3">
                    <span id="fileName" class="badge bg-sebi-navy"></span>
                </div>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
                <button type="button" class="btn btn-sebi-primary" onclick="confirmImageUpload()">
                    <i class="fas fa-upload me-1"></i> Upload & Send
                </button>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script src="{{ url_for('static', filename='js/speech.js') }}"></script>
<script>
// Global variables
const sessionId = {{ session_id }};
let socket = null;
let currentFileInfo = null;
let isRecording = false;
let speechRecognition = null;

// Initialize when page loads
document.addEventListener('DOMContentLoaded', function() {
    initializeSocket();
    initializeFileUpload();
    scrollToBottom();
});

function initializeSocket() {
    socket = io();
    
    socket.on('connect', function() {
        console.log('Connected to server');
        socket.emit('join_session', {session_id: sessionId});
    });
    
    socket.on('new_message', function(data) {
        displayMessage(data);
        scrollToBottom();
    });
    
    socket.on('ai_response_start', function(data) {
        showTypingIndicator();
    });
    
    socket.on('ai_response_chunk', function(data) {
        updateStreamingResponse(data);
    });
    
    socket.on('ai_response_end', function(data) {
        hideTypingIndicator();
        displayMessage(data);
        scrollToBottom();
    });
    
    socket.on('error', function(data) {
        showError(data.message);
    });
    
    socket.on('speech_result', function(data) {
        updateTranscription(data);
    });
    
    socket.on('speech_error', function(data) {
        showError('Speech recognition error: ' + data.message);
        stopRecording();
    });
}

function initializeFileUpload() {
    const fileInput = document.getElementById('fileInput');
    fileInput.addEventListener('change', handleFileSelect);
    
    // Drag and drop functionality
    const chatMessages = document.getElementById('chatMessages');
    chatMessages.addEventListener('dragover', handleDragOver);
    chatMessages.addEventListener('drop', handleFileDrop);
}

function handleKeyPress(event) {
    if (event.key === 'Enter' && !event.shiftKey) {
        event.preventDefault();
        sendMessage();
    }
}

function sendMessage() {
    const messageInput = document.getElementById('messageInput');
    const message = messageInput.value.trim();
    
    if (!message && !currentFileInfo) {
        return;
    }
    
    // Disable send button temporarily
    const sendBtn = document.getElementById('sendBtn');
    sendBtn.disabled = true;
    
    socket.emit('send_message', {
        session_id: sessionId,
        message: message,
        type: currentFileInfo ? 'image' : 'text',
        file_info: currentFileInfo
    });
    
    // Clear input and file info
    messageInput.value = '';
    currentFileInfo = null;
    
    setTimeout(() => {
        sendBtn.disabled = false;
    }, 1000);
}

function displayMessage(messageData) {
    const chatMessages = document.getElementById('chatMessages');
    const messageDiv = document.createElement('div');
    messageDiv.className = `message message-${messageData.type}`;
    
    const time = new Date(messageData.timestamp).toLocaleTimeString('en-US', {
        hour: '2-digit',
        minute: '2-digit'
    });
    
    messageDiv.innerHTML = `
        <div class="message-header">
            <i class="fas fa-${messageData.type === 'user' ? 'user' : 'robot'} me-1"></i>
            ${messageData.type === 'user' ? 'You' : 'AI Tutor'}
            <span class="text-muted ms-2">${time}</span>
        </div>
        <div class="message-bubble">
            ${messageData.file_info ? `
                <div class="mb-2">
                    <i class="fas fa-image me-1"></i>
                    ${messageData.file_info.original_name}
                </div>
            ` : ''}
            ${messageData.content}
        </div>
    `;
    
    chatMessages.appendChild(messageDiv);
}

function showTypingIndicator() {
    const chatMessages = document.getElementById('chatMessages');
    const typingDiv = document.createElement('div');
    typingDiv.className = 'message message-ai';
    typingDiv.id = 'typingIndicator';
    
    typingDiv.innerHTML = `
        <div class="message-header">
            <i class="fas fa-robot me-1"></i> AI Tutor
        </div>
        <div class="typing-indicator">
            <div class="typing-dots">
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
            </div>
        </div>
    `;
    
    chatMessages.appendChild(typingDiv);
    scrollToBottom();
}

function hideTypingIndicator() {
    const typingIndicator = document.getElementById('typingIndicator');
    if (typingIndicator) {
        typingIndicator.remove();
    }
}

function scrollToBottom() {
    const chatMessages = document.getElementById('chatMessages');
    chatMessages.scrollTop = chatMessages.scrollHeight;
}

function showError(message) {
    const alert = document.createElement('div');
    alert.className = 'alert alert-danger alert-dismissible fade show';
    alert.innerHTML = `
        ${message}
        <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
    `;
    
    document.querySelector('.container').insertBefore(alert, document.querySelector('.chat-container'));
    
    setTimeout(() => {
        if (alert.parentNode) {
            alert.remove();
        }
    }, 5000);
}

// File upload functions
function handleFileSelect(event) {
    const file = event.target.files[0];
    if (file) {
        previewImage(file);
    }
}

function handleDragOver(event) {
    event.preventDefault();
    event.dataTransfer.dropEffect = 'copy';
}

function handleFileDrop(event) {
    event.preventDefault();
    const files = event.dataTransfer.files;
    if (files.length > 0) {
        previewImage(files[0]);
    }
}

function previewImage(file) {
    if (file.size > 5 * 1024 * 1024) {
        showError('File too large. Please upload images under 5MB.');
        return;
    }
    
    const reader = new FileReader();
    reader.onload = function(e) {
        document.getElementById('previewImage').src = e.target.result;
        document.getElementById('fileName').textContent = file.name;
        new bootstrap.Modal(document.getElementById('imagePreviewModal')).show();
    };
    reader.readAsDataURL(file);
    
    // Store file for upload
    window.pendingFile = file;
}

function confirmImageUpload() {
    const file = window.pendingFile;
    if (!file) return;
    
    const formData = new FormData();
    formData.append('file', file);
    
    // Show upload status
    const uploadStatus = document.getElementById('uploadStatus');
    uploadStatus.classList.remove('d-none');
    
    fetch('/upload_image', {
        method: 'POST',
        body: formData
    })
    .then(response => response.json())
    .then(data => {
        uploadStatus.classList.add('d-none');
        
        if (data.success) {
            currentFileInfo = data;
            document.getElementById('messageInput').placeholder = `Image uploaded: ${data.original_name}. Type your question...`;
            bootstrap.Modal.getInstance(document.getElementById('imagePreviewModal')).hide();
        } else {
            showError(data.error);
        }
    })
    .catch(error => {
        uploadStatus.classList.add('d-none');
        showError('Upload failed. Please try again.');
    });
}

// Voice functions
function toggleRecording() {
    if (isRecording) {
        stopRecording();
    } else {
        startRecording();
    }
}

function startRecording() {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        showError('Speech recognition not supported in this browser.');
        return;
    }
    
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    speechRecognition = new SpeechRecognition();
    
    speechRecognition.continuous = true;
    speechRecognition.interimResults = true;
    speechRecognition.lang = getCurrentLanguage();
    
    speechRecognition.onstart = function() {
        isRecording = true;
        updateVoiceButton();
        showVoiceStatus();
    };
    
    speechRecognition.onresult = function(event) {
        let interimTranscript = '';
        let finalTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
                finalTranscript += transcript;
            } else {
                interimTranscript += transcript;
            }
        }
        
        const preview = document.getElementById('transcriptionPreview');
        preview.textContent = finalTranscript + interimTranscript;
        
        if (finalTranscript) {
            document.getElementById('messageInput').value = finalTranscript;
        }
    };
    
    speechRecognition.onerror = function(event) {
        showError('Speech recognition error: ' + event.error);
        stopRecording();
    };
    
    speechRecognition.onend = function() {
        stopRecording();
    };
    
    speechRecognition.start();
}

function stopRecording() {
    if (speechRecognition) {
        speechRecognition.stop();
    }
    
    isRecording = false;
    updateVoiceButton();
    hideVoiceStatus();
}

function updateVoiceButton() {
    const voiceBtn = document.getElementById('voiceBtn');
    const icon = voiceBtn.querySelector('i');
    
    if (isRecording) {
        voiceBtn.classList.add('btn-danger');
        voiceBtn.classList.remove('btn-outline-sebi-navy');
        icon.className = 'fas fa-stop';
    } else {
        voiceBtn.classList.remove('btn-danger');
        voiceBtn.classList.add('btn-outline-sebi-navy');
        icon.className = 'fas fa-microphone';
    }
}

function showVoiceStatus() {
    document.getElementById('voiceStatus').classList.remove('d-none');
}

function hideVoiceStatus() {
    document.getElementById('voiceStatus').classList.add('d-none');
    document.getElementById('transcriptionPreview').textContent = '';
}

function getCurrentLanguage() {
    return localStorage.getItem('selectedLanguage') || 'en-US';
}

// Language functions
function changeLanguage(langCode, langName) {
    localStorage.setItem('selectedLanguage', langCode);
    document.getElementById('current-language').textContent = langName;
    
    fetch('/set_language', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({language: langCode})
    });
}

// Quick action functions
function askFollowUp() {
    document.getElementById('messageInput').value = 'Can you explain this in more detail?';
    document.getElementById('messageInput').focus();
}

function takeNotes() {
    showError('Note-taking feature coming soon!');
}

function readAloud() {
    const lastAiMessage = document.querySelector('.message-ai:last-of-type .message-bubble');
    if (lastAiMessage && 'speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(lastAiMessage.textContent);
        utterance.lang = getCurrentLanguage().replace('-', '_');
        speechSynthesis.speak(utterance);
    } else {
        showError('Speech synthesis not available.');
    }
}
</script>
{% endblock %}
